{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_ASSIGNMENT_JUL_2022_HW.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPgypsuzZR1pKZ/v7ibea6U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prahladpunia/AI/blob/main/BERT_ASSIGNMENT_JUL_2022_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "CJ1lASmMMr9n"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data and set labels\n",
        "train = pd.read_csv('/content/train_2kmZucJ.csv')\n",
        "# Display 5 random samples\n",
        "train.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "aYqVPVxAM1Hu",
        "outputId": "231504f4-c02b-4426-80e5-c3c55a21dbfe"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id  label                                              tweet\n",
              "4896  4897      0  Photo: cause we both dressed up today  #boyfr...\n",
              "7539  7540      1  @skullcandy your product is brutal, 1 headphon...\n",
              "1677  1678      0  Sunset Today in Zeeland ;-) Samsung Mobile S4 ...\n",
              "1964  1965      0  God $&@*# it playstation share feature!! Cutti...\n",
              "3025  3026      0  Awe he's da bestest :) #boyfriend him #iloveyo..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1178f81-b681-4707-b9c1-2853821090b4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4896</th>\n",
              "      <td>4897</td>\n",
              "      <td>0</td>\n",
              "      <td>Photo: cause we both dressed up today  #boyfr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7539</th>\n",
              "      <td>7540</td>\n",
              "      <td>1</td>\n",
              "      <td>@skullcandy your product is brutal, 1 headphon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1677</th>\n",
              "      <td>1678</td>\n",
              "      <td>0</td>\n",
              "      <td>Sunset Today in Zeeland ;-) Samsung Mobile S4 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1964</th>\n",
              "      <td>1965</td>\n",
              "      <td>0</td>\n",
              "      <td>God $&amp;@*# it playstation share feature!! Cutti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3025</th>\n",
              "      <td>3026</td>\n",
              "      <td>0</td>\n",
              "      <td>Awe he's da bestest :) #boyfriend him #iloveyo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1178f81-b681-4707-b9c1-2853821090b4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d1178f81-b681-4707-b9c1-2853821090b4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d1178f81-b681-4707-b9c1-2853821090b4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = train.tweet.values\n",
        "y = train.label.values\n",
        "\n",
        "X_train, X_val, y_train, y_val =\\\n",
        "    train_test_split(X, y, test_size=0.1, random_state=2020)"
      ],
      "metadata": {
        "id": "yS7yVf0kR9GG"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test data\n",
        "test = pd.read_csv('/content/test_12QyDcx.csv')\n",
        "\n",
        "# Keep important columns\n",
        "test = test[['id', 'tweet']]\n",
        "\n",
        "# Display 5 samples from the test data\n",
        "test.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cajiW58XT9Uu",
        "outputId": "a3694940-a90c-4bde-dcf8-6a6d629d74ba"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                              tweet\n",
              "1402  9323  For a #phone #samsung #galaxy #s5 #galaxys5 i ...\n",
              "1328  9249  Got my Xmas present from parents today! xD HAP...\n",
              "1140  9061  Finally, my new Note 3 #finally #samsung #gala...\n",
              "134   8055  Woooo apple store in Rundle Mall lol jks burn,...\n",
              "1016  8937  Happy happy happy... new phone :) #samsung #ga..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90893fdd-f43d-4b24-8d43-d27e580837d5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1402</th>\n",
              "      <td>9323</td>\n",
              "      <td>For a #phone #samsung #galaxy #s5 #galaxys5 i ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1328</th>\n",
              "      <td>9249</td>\n",
              "      <td>Got my Xmas present from parents today! xD HAP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1140</th>\n",
              "      <td>9061</td>\n",
              "      <td>Finally, my new Note 3 #finally #samsung #gala...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>8055</td>\n",
              "      <td>Woooo apple store in Rundle Mall lol jks burn,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1016</th>\n",
              "      <td>8937</td>\n",
              "      <td>Happy happy happy... new phone :) #samsung #ga...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90893fdd-f43d-4b24-8d43-d27e580837d5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-90893fdd-f43d-4b24-8d43-d27e580837d5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-90893fdd-f43d-4b24-8d43-d27e580837d5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swFDHXTJWfad",
        "outputId": "bcfa002f-104c-4b5a-eee3-80b6cc632015"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#- Baseline: TF-IDF + Naive Bayes Classifier"
      ],
      "metadata": {
        "id": "74pApPnFd7ot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation   \n",
        "## Preprocessing"
      ],
      "metadata": {
        "id": "7q-wEJJieCzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "# Uncomment to download \"stopwords\"\n",
        "# nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def text_preprocessing(s):\n",
        "    \"\"\"\n",
        "    - Lowercase the sentence\n",
        "    - Change \"'t\" to \"not\"\n",
        "    - Remove \"@name\"\n",
        "    - Isolate and remove punctuations except \"?\"\n",
        "    - Remove other special characters\n",
        "    - Remove stop words except \"not\" and \"can\"\n",
        "    - Remove trailing whitespace\n",
        "    \"\"\"\n",
        "    s = s.lower()\n",
        "    # Change 't to 'not'\n",
        "    s = re.sub(r\"\\'t\", \" not\", s)\n",
        "    # Remove @name\n",
        "    s = re.sub(r'(@.*?)[\\s]', ' ', s)\n",
        "    # Isolate and remove punctuations except '?'\n",
        "    s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\\\\\/\\,])', r' \\1 ', s)\n",
        "    s = re.sub(r'[^\\w\\s\\?]', ' ', s)\n",
        "    # Remove some special characters\n",
        "    s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
        "    # Remove stopwords except 'not' and 'can'\n",
        "    s = \" \".join([word for word in s.split()\n",
        "                  if word not in stopwords.words('english')\n",
        "                  or word in ['not', 'can']])\n",
        "    # Remove trailing whitespace\n",
        "    s = re.sub(r'\\s+', ' ', s).strip()\n",
        "    \n",
        "    return s"
      ],
      "metadata": {
        "id": "n4XOqTVsd-sP"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  TF-IDF Vectorizer"
      ],
      "metadata": {
        "id": "mhssmmmbeQsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "nltk.download('stopwords')\n",
        "# Preprocess text\n",
        "X_train_preprocessed = np.array([text_preprocessing(text) for text in X_train])\n",
        "X_val_preprocessed = np.array([text_preprocessing(text) for text in X_val])\n",
        "\n",
        "# Calculate TF-IDF\n",
        "tf_idf = TfidfVectorizer(smooth_idf=False)\n",
        "X_train_tfidf = tf_idf.fit_transform(X_train_preprocessed)\n",
        "X_val_tfidf = tf_idf.transform(X_val_preprocessed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtyI1yvzeIEP",
        "outputId": "9fad086e-17fb-41f7-fe2d-ae58ca22a81a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 13.9 s, sys: 1.44 s, total: 15.4 s\n",
            "Wall time: 15.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk0cAjuYhy7t",
        "outputId": "0fcd6d46-c72f-4dd8-ca5c-cbfdda71fafd"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_preprocessed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwnJKu3plGQh",
        "outputId": "856a7f95-715f-4d93-e53e-ec99969fa35f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['new phone cover prettier ariel iphone iphone5 disney apple underthesea aw cute pic twitter com 7mqhg8lpby',\n",
              "       'wow lost 2 500 photos apple shut fuck',\n",
              "       'new iphone theme appleton cydia monty macciti com 1200 downloads already going join',\n",
              "       ...,\n",
              "       'photo new stunning pretty cute gorgeous beauty ig iphone ignation instahub http tmblr co zonpawppb83_',\n",
              "       'darling soon married couple iphone instagram http instagr p jo7gq',\n",
              "       'taking extra credit survey phone literally giving apple worst reviews ever o____o whydoihaveaniphone'],\n",
              "      dtype='<U351')"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Naive Bayes Classifier\n",
        "## Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "ycoNhPZ_esPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "def get_auc_CV(model):\n",
        "    \"\"\"\n",
        "    Return the average AUC score from cross-validation.\n",
        "    \"\"\"\n",
        "    # Set KFold to shuffle data before the split\n",
        "    kf = StratifiedKFold(5, shuffle=True, random_state=1)\n",
        "\n",
        "    # Get AUC scores\n",
        "    auc = cross_val_score(\n",
        "        model, X_train_tfidf, y_train, scoring=\"roc_auc\", cv=kf)\n",
        "\n",
        "    return auc.mean()"
      ],
      "metadata": {
        "id": "5lkquCt4eIG2"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = pd.Series([get_auc_CV(MultinomialNB(i)) for i in np.arange(1, 10, 0.1)],\n",
        "                   index=np.arange(1, 10, 0.1))\n",
        "best_alpha = np.round(res.idxmax(),2)\n",
        "print('Best alpha: ', best_alpha)\n",
        "\n",
        "plt.plot(res)\n",
        "plt.title('AUC vs. Alpha')\n",
        "plt.xlabel('Alpha')\n",
        "plt.ylabel('AUC')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "k4pgV0Y_ewSY",
        "outputId": "730faa73-43c8-4e2c-c968-15e5d9afa4b5"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-99a02d287c76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m res = pd.Series([get_auc_CV(MultinomialNB(i)) for i in np.arange(1, 10, 0.1)],\n\u001b[0m\u001b[1;32m      2\u001b[0m                    index=np.arange(1, 10, 0.1))\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best alpha: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_alpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-75-99a02d287c76>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m res = pd.Series([get_auc_CV(MultinomialNB(i)) for i in np.arange(1, 10, 0.1)],\n\u001b[0m\u001b[1;32m      2\u001b[0m                    index=np.arange(1, 10, 0.1))\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best alpha: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_alpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 2 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.2. Evaluation on Validation Set"
      ],
      "metadata": {
        "id": "0VA_lQGum4Ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
        "\n",
        "def evaluate_roc(probs, y_true):\n",
        "    \"\"\"\n",
        "    - Print AUC and accuracy on the test set\n",
        "    - Plot ROC\n",
        "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
        "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
        "    \"\"\"\n",
        "    preds = probs[:, 1]\n",
        "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(f'AUC: {roc_auc:.4f}')\n",
        "       \n",
        "    # Get accuracy over the test set\n",
        "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
        "    \n",
        "    # Plot ROC AUC\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "    plt.legend(loc = 'lower right')\n",
        "    plt.plot([0, 1], [0, 1],'r--')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "gKujohaeewWc"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute predicted probabilities\n",
        "nb_model = MultinomialNB(alpha=1.8)\n",
        "nb_model.fit(X_train_tfidf, y_train)\n",
        "probs = nb_model.predict_proba(X_val_tfidf)\n",
        "\n",
        "# Evaluate the classifier\n",
        "evaluate_roc(probs, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "IBScwfo0m6ng",
        "outputId": "3862801f-2378-432a-cc9f-c8f0b81c13f7"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 0.9465\n",
            "Accuracy: 80.81%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "E-ASvdVym6qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "W4rs5dqVeILa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT"
      ],
      "metadata": {
        "id": "LzR8JoqSnPV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment the line below to install `transformers`\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "716pC0YvWobM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TOKENIZATION\n",
        "def text_preprocessing(text):\n",
        "    \"\"\"\n",
        "    - Remove entity mentions (eg. '@united')\n",
        "    - Correct errors (eg. '&amp;' to '&')\n",
        "    @param    text (str): a string to be processed.\n",
        "    @return   text (Str): the processed string.\n",
        "    \"\"\"\n",
        "    # Remove '@name'\n",
        "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
        "\n",
        "    # Replace '&amp;' with '&'\n",
        "    text = re.sub(r'&amp;', '&', text)\n",
        "\n",
        "    # Remove trailing whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "I45eNllqW3Gf"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print sentence 0\n",
        "print('Original: ', X[0])\n",
        "print('Processed: ', text_preprocessing(X[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVjaFknHW9j_",
        "outputId": "ef382e31-e6b8-4ad7-c7e9-0abe6a65dd3b"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  #fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone\n",
            "Processed:  #fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# Create a function to tokenize a set of texts\n",
        "def preprocessing_for_bert(data):\n",
        "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                  tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in data:\n",
        "        # `encode_plus` will:\n",
        "        #    (1) Tokenize the sentence\n",
        "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
        "        #    (3) Truncate/Pad sentence to max length\n",
        "        #    (4) Map tokens to their IDs\n",
        "        #    (5) Create attention mask\n",
        "        #    (6) Return a dictionary of outputs\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text=text_preprocessing(sent),  # Preprocess sentence\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
        "            pad_to_max_length=True,         # Pad sentence to max length\n",
        "            #return_tensors='pt',           # Return PyTorch tensor\n",
        "            return_attention_mask=True      # Return attention mask\n",
        "            )\n",
        "        \n",
        "        # Add the outputs to the lists\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks\n"
      ],
      "metadata": {
        "id": "Qip3FW1IXNDR"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate train data and test data\n",
        "all_tweets = np.concatenate([train.tweet.values, test.tweet.values])\n",
        "\n",
        "# Encode our concatenated data\n",
        "encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_tweets]\n",
        "\n",
        "# Find the maximum length\n",
        "max_len = max([len(sent) for sent in encoded_tweets])\n",
        "print('Max length: ', max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6X7PcJkpXfhD",
        "outputId": "a148e6a0-86f3-4881-907a-618a2388262b"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max length:  142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify `MAX_LEN`\n",
        "MAX_LEN = 100\n",
        "\n",
        "# Print sentence 0 and its encoded token ids\n",
        "token_ids = list(preprocessing_for_bert([X[0]])[0].squeeze().numpy())\n",
        "print('Original: ', X[0])\n",
        "print('Token IDs: ', token_ids)\n",
        "\n",
        "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
        "print('Tokenizing data...')\n",
        "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
        "val_inputs, val_masks = preprocessing_for_bert(X_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx-fzZ5FX_FX",
        "outputId": "88907b2e-30ba-47c4-9b29-c121a8c40154"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  #fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone\n",
            "Token IDs:  [101, 1001, 4344, 16550, 1001, 10032, 3231, 16770, 1024, 1013, 1013, 27571, 1012, 1043, 2140, 1013, 1044, 2487, 2213, 2546, 4160, 2615, 1001, 11924, 1001, 18726, 1001, 3376, 1001, 10140, 1001, 2740, 1001, 1045, 15776, 1001, 18059, 2239, 2135, 1001, 18059, 8464, 1001, 18059, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Tokenizing data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create PyTorch DataLoader"
      ],
      "metadata": {
        "id": "FvNZd92HYNxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Convert other data types to torch.Tensor\n",
        "train_labels = torch.tensor(y_train)\n",
        "val_labels = torch.tensor(y_val)\n",
        "\n",
        "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "yCm286gJYSCi"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Our Model    \n",
        "### Create BertClassifier"
      ],
      "metadata": {
        "id": "e_-IF46uYfIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "# Create the BertClassfier class\n",
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "        super(BertClassifier, self).__init__()\n",
        "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "        D_in, H, D_out = 768, 50, 2\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(D_in, H),\n",
        "            nn.ReLU(),\n",
        "            #nn.Dropout(0.5),\n",
        "            nn.Linear(H, D_out)\n",
        "        )\n",
        "\n",
        "        # Freeze the BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        # Feed input to BERT\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "        \n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQmAGdgeYcB-",
        "outputId": "58803b41-70f5-42d9-c31a-edd3c55f5b82"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 48 µs, sys: 1e+03 ns, total: 49 µs\n",
            "Wall time: 53.6 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizer & Learning Rate Scheduler"
      ],
      "metadata": {
        "id": "rEVdD95HYxkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "def initialize_model(epochs=4):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = BertClassifier(freeze_bert=False)\n",
        "\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\n",
        "                      lr=5e-5,    # Default learning rate\n",
        "                      eps=1e-8    # Default epsilon value\n",
        "                      )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler"
      ],
      "metadata": {
        "id": "iVsFp7JIYzNw"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop"
      ],
      "metadata": {
        "id": "0LjI1RU0ZLGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "\n",
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            \n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    print(\"Training complete!\")\n",
        "\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy\n"
      ],
      "metadata": {
        "id": "6Sw2HRFoZMuy"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's start training our BertClassifier!"
      ],
      "metadata": {
        "id": "Jw9_0AmsZgdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)    # Set seed for reproducibility\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
        "train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swXAyh15ZhdM",
        "outputId": "e9a72b47-3de6-4743-f356-09173a3d4dd7"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.412347   |     -      |     -     |   11.73  \n",
            "   1    |   40    |   0.274433   |     -      |     -     |   11.55  \n",
            "   1    |   60    |   0.275089   |     -      |     -     |   11.54  \n",
            "   1    |   80    |   0.236505   |     -      |     -     |   11.21  \n",
            "   1    |   100   |   0.186598   |     -      |     -     |   11.01  \n",
            "   1    |   120   |   0.189909   |     -      |     -     |   10.91  \n",
            "   1    |   140   |   0.172079   |     -      |     -     |   10.90  \n",
            "   1    |   160   |   0.274152   |     -      |     -     |   10.96  \n",
            "   1    |   180   |   0.258403   |     -      |     -     |   11.04  \n",
            "   1    |   200   |   0.226624   |     -      |     -     |   11.12  \n",
            "   1    |   220   |   0.245854   |     -      |     -     |   11.14  \n",
            "   1    |   222   |   0.192840   |     -      |     -     |   0.99   \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   0.250394   |  0.209659  |   91.42   |  129.19  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.132773   |     -      |     -     |   11.62  \n",
            "   2    |   40    |   0.143293   |     -      |     -     |   11.04  \n",
            "   2    |   60    |   0.126050   |     -      |     -     |   11.00  \n",
            "   2    |   80    |   0.177604   |     -      |     -     |   10.99  \n",
            "   2    |   100   |   0.142150   |     -      |     -     |   11.01  \n",
            "   2    |   120   |   0.146064   |     -      |     -     |   11.03  \n",
            "   2    |   140   |   0.138007   |     -      |     -     |   11.05  \n",
            "   2    |   160   |   0.175711   |     -      |     -     |   11.07  \n",
            "   2    |   180   |   0.152917   |     -      |     -     |   11.05  \n",
            "   2    |   200   |   0.162536   |     -      |     -     |   11.08  \n",
            "   2    |   220   |   0.154235   |     -      |     -     |   11.09  \n",
            "   2    |   222   |   0.309361   |     -      |     -     |   0.97   \n",
            "----------------------------------------------------------------------\n",
            "   2    |    -    |   0.151472   |  0.219424  |   91.79   |  128.05  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation on Validation Set"
      ],
      "metadata": {
        "id": "Z7mxNqO_ZuGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute predicted probabilities on the test set\n",
        "# Please initialize function `bert_predict` by running the first cell in Section 4.2.\n",
        "probs = bert_predict(bert_classifier, val_dataloader)\n",
        "\n",
        "# Evaluate the Bert classifier\n",
        "evaluate_roc(probs, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "0EY6pI8bZvko",
        "outputId": "e4eecd53-28be-4d97-c6a3-603cb6836f27"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 0.9651\n",
            "Accuracy: 91.79%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Our Model on the Entire Training Data"
      ],
      "metadata": {
        "id": "MsWZYWMuZ5G_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate the train set and the validation set\n",
        "full_train_data = torch.utils.data.ConcatDataset([train_data, val_data])\n",
        "full_train_sampler = RandomSampler(full_train_data)\n",
        "full_train_dataloader = DataLoader(full_train_data, sampler=full_train_sampler, batch_size=32)\n",
        "\n",
        "# Train the Bert Classifier on the entire training data\n",
        "set_seed(42)\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
        "train(bert_classifier, full_train_dataloader, epochs=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZCmuKQ9Z6aZ",
        "outputId": "87934b86-e745-4bc9-9374-085e7335cfbe"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.409503   |     -      |     -     |   11.62  \n",
            "   1    |   40    |   0.291405   |     -      |     -     |   11.45  \n",
            "   1    |   60    |   0.253878   |     -      |     -     |   11.56  \n",
            "   1    |   80    |   0.242667   |     -      |     -     |   11.23  \n",
            "   1    |   100   |   0.261070   |     -      |     -     |   11.05  \n",
            "   1    |   120   |   0.213717   |     -      |     -     |   10.91  \n",
            "   1    |   140   |   0.239449   |     -      |     -     |   10.87  \n",
            "   1    |   160   |   0.250091   |     -      |     -     |   10.93  \n",
            "   1    |   180   |   0.185655   |     -      |     -     |   11.04  \n",
            "   1    |   200   |   0.217458   |     -      |     -     |   11.13  \n",
            "   1    |   220   |   0.183074   |     -      |     -     |   11.16  \n",
            "   1    |   240   |   0.203815   |     -      |     -     |   11.12  \n",
            "   1    |   247   |   0.152677   |     -      |     -     |   3.63   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.152552   |     -      |     -     |   11.77  \n",
            "   2    |   40    |   0.194092   |     -      |     -     |   11.00  \n",
            "   2    |   60    |   0.130374   |     -      |     -     |   11.00  \n",
            "   2    |   80    |   0.161239   |     -      |     -     |   11.03  \n",
            "   2    |   100   |   0.165676   |     -      |     -     |   11.02  \n",
            "   2    |   120   |   0.124285   |     -      |     -     |   11.04  \n",
            "   2    |   140   |   0.147554   |     -      |     -     |   11.05  \n",
            "   2    |   160   |   0.135884   |     -      |     -     |   11.04  \n",
            "   2    |   180   |   0.156338   |     -      |     -     |   11.05  \n",
            "   2    |   200   |   0.139441   |     -      |     -     |   11.05  \n",
            "   2    |   220   |   0.136214   |     -      |     -     |   11.07  \n",
            "   2    |   240   |   0.155203   |     -      |     -     |   11.06  \n",
            "   2    |   247   |   0.188346   |     -      |     -     |   3.62   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions on Test Set     \n",
        "## Data Preparation"
      ],
      "metadata": {
        "id": "vXnjTBSJaB1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "saYa02zfaDY6",
        "outputId": "579675a2-57d2-4742-d1f0-55f50a9ad9aa"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                              tweet\n",
              "1616  9537  I when #people #hashtag their whole #tweet. An...\n",
              "1407  9328  Got that Galaxy S8!! #smartphone #newstuff #so...\n",
              "976   8897  There's gonna be so many Apple probs tomorrow ...\n",
              "1057  8978  Photo: My Sunday morning… #vscocam #kids #smil...\n",
              "307   8228  Sister got an iPad for her birthday & she's 8!..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9509fa89-e7e3-47d0-ad39-916ac07bcc7b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1616</th>\n",
              "      <td>9537</td>\n",
              "      <td>I when #people #hashtag their whole #tweet. An...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1407</th>\n",
              "      <td>9328</td>\n",
              "      <td>Got that Galaxy S8!! #smartphone #newstuff #so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>976</th>\n",
              "      <td>8897</td>\n",
              "      <td>There's gonna be so many Apple probs tomorrow ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1057</th>\n",
              "      <td>8978</td>\n",
              "      <td>Photo: My Sunday morning… #vscocam #kids #smil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307</th>\n",
              "      <td>8228</td>\n",
              "      <td>Sister got an iPad for her birthday &amp; she's 8!...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9509fa89-e7e3-47d0-ad39-916ac07bcc7b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9509fa89-e7e3-47d0-ad39-916ac07bcc7b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9509fa89-e7e3-47d0-ad39-916ac07bcc7b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run `preprocessing_for_bert` on the test set\n",
        "print('Tokenizing data...')\n",
        "test_inputs, test_masks = preprocessing_for_bert(test.tweet)\n",
        "\n",
        "# Create the DataLoader for our test set\n",
        "test_dataset = TensorDataset(test_inputs, test_masks)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FylgW5eTaV4m",
        "outputId": "5a670071-8de8-47bd-9607-bc1d1ffe7366"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Predictions"
      ],
      "metadata": {
        "id": "GLoloLATadln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    all_logits = []\n",
        "\n",
        "    # For each batch in our test set...\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "        all_logits.append(logits)\n",
        "    \n",
        "    # Concatenate logits from each batch\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "\n",
        "    # Apply softmax to calculate probabilities\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "\n",
        "    return probs"
      ],
      "metadata": {
        "id": "uQoz_GQqafGg"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute predicted probabilities on the test set\n",
        "probs = bert_predict(bert_classifier, test_dataloader)\n",
        "\n",
        "# Get predictions from the probabilities\n",
        "threshold = 0.6\n",
        "preds = np.where(probs[:, 1] > threshold, 1, 0)\n",
        "\n",
        "# Number of tweets predicted non-negative\n",
        "print(\"Number of tweets predicted non-negative: \", preds.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uYhFOsIap4d",
        "outputId": "6d48587b-e74f-46a4-e23a-9645082ad62f"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tweets predicted non-negative:  578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XpXCTImtv-O",
        "outputId": "9b468b13-99c9-4ee5-8112-51b1d9e9f812"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = test[preds==0]\n",
        "list(output.sample(20).tweet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIr6VDM2awxD",
        "outputId": "03754338-42ce-4492-f860-fe8d0dfc4f45"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"My day's got even better, I've just found my #Samsung tablet!! It's been right under my nose all of this time.\",\n",
              " 'Okay fuck you too Siri... #trouble #in #paradise #$&@*# #lol #iphone http://instagr.am/p/QsA2TsH1vT/',\n",
              " '➊ #FOLLOWTRICK ➋ RETWEET ➌ FOLLOW ALL WHO RT ➍ #FOLLOWBACK ➎ GAIN TODAY #iphone #sougofollow ¤6g?',\n",
              " 'Photo: #quotes #instagood #insta$&@*# #sexy #weed #iphone #cute #kicks #summer #lol #fresh #picoftheday... http://tmblr.co/Z0yp6vX2nqTD',\n",
              " '#me #boy #gay #dreams #nite #hamaca #mexico #yucatan #man #iphone loveeee http://instagram.com/p/vIEDdotNfe/',\n",
              " 'STAMFORD BRIDGE. #stamford #england #chelsea #minion #samsung #davidluiz #bieber #minions… http://instagram.com/p/eAuoxskrlT/',\n",
              " \"#new #iphone #case #queen #of #texting my #mum #pink #cute #christmas hasn't ended!!! http://instagr.am/p/TwWsApE6RO/\",\n",
              " 'Quality Time #samsung #opudepartement #fun #joyfull @ Bandar Jakarta Resto Summarecon… https://instagram.com/p/9a-1woI0zt/',\n",
              " 'Lovely day Lovely shoot by @javafinger #couple #isengsenang #a7r #sony… https://instagram.com/p/6hMKAmRj4o/',\n",
              " 'Beautiful blue skies in London this morning #stylist #london #studio #shoot #sony #gaming @… https://instagram.com/p/25Oj1DLiwG/',\n",
              " 'Uhm who has the sweetest/best #boyfriend ever? Me #iphone #text #cute #boh #couple #sweet #forever http://instagr.am/p/NWXUbGEIOP/',\n",
              " 'New phone case #phone #case #sony #xperia #england #keep #calm #and #carry #on #nofilter… http://instagram.com/p/cgaJeyxn3E/',\n",
              " 'How cute is my phone!! #instapic #icons #iphone #4s #app #instagram #pink #girl #stripes #sunday… http://instagr.am/p/Vjui2wAjSy/',\n",
              " 'Until next Thurs 6pm \"Who\\'s on your Love Shopping List\" http://ask.fm/LSLLoveAdvice #DrAndrew #Relationships #Dating #iPhone',\n",
              " 'Happy Brother and Sister #brother #sister #superwet #vinkeveen #vinkeveenseplassen #nautique #wakeboarden #liquidforce #liquidforcenederland #redbullned #gopro #redbull #samsung… https://www.instagram.com/p/BkmS3YdAOO9/?utm_source=ig_twitter_share&igshid=1sxk779d9k66l …',\n",
              " 'Different strokes for different folks! #GrandPrimePlus comes in four different colors. #Samsung #NewPhone ... http://fb.me/16KCo4Mo9',\n",
              " 'Do you love your #smartphone? Emotionally, ? Better read this. http://www.Ingenuity.Guru #hightech #hipster #iPhone #Android',\n",
              " 'Photo: My Sunday morning… #vscocam #kids #smile #Sunday #wefie #instagram #instaplace #Jakarta #Sony... http://tmblr.co/ZcJ-vx1Xy7KI-',\n",
              " 'My New Toy. Samsung Galaxy s3 mini. #Samsung #s3 #mini #white #new #yeahhhhhpic.twitter.com/Mx2NssAfZg',\n",
              " 'Just straight killing en. http://www.mixer.com/samtherice http://www.twitch.tv/samtherice #twitch #stream #mixer #gaming #games #youtube #live #supportsmallstreamers #watch #streaming #New #fun #veriaty #veriatystream #watchmixer #asianstreamer #twitchkittens #arenaofvalor #aov #iphonex pic.twitter.com/bcEmCJNNfz']"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub = pd.read_csv(\"/content/sample_submission_LnhVWA4.csv\")"
      ],
      "metadata": {
        "id": "ycTMvYOms62s"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fw480VF7tBeI",
        "outputId": "2eb6dbb7-0343-4428-daad-4d92b728ee02"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     id  label\n",
              "0  7921      0\n",
              "1  7922      0\n",
              "2  7923      0\n",
              "3  7924      0\n",
              "4  7925      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-66ebde45-019f-4d41-aef0-55bf374e429c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7921</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7922</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7923</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7924</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7925</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66ebde45-019f-4d41-aef0-55bf374e429c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-66ebde45-019f-4d41-aef0-55bf374e429c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-66ebde45-019f-4d41-aef0-55bf374e429c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5WvYOPzwPJv",
        "outputId": "c87216ad-433b-4886-d938-bcb2655cd9d3"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1953, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub[\"label\"]= preds"
      ],
      "metadata": {
        "id": "ZoYO-NoStFI5"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBGXJmXeuBOu",
        "outputId": "11b1552c-d18d-4549-b4ad-75b00eb463cb"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1953, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub.to_csv(\"submission1.csv\", index=False)"
      ],
      "metadata": {
        "id": "kYSK5kK2vE9h"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dt.to_csv('file_name.csv',index=False)"
      ],
      "metadata": {
        "id": "eairb3v_uNST"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}